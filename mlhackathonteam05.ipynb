{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1cRks9RUmYE9djgVl1ihkyV7Jd8xkiMW4",
      "authorship_tag": "ABX9TyMeN8J5j6h7gWpDm+CHPf9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shr8769/ML-HACKATHON-TEAM15/blob/main/mlhackathonteam05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MLab084W_BnP"
      },
      "outputs": [],
      "source": [
        "# === CELL 1: Imports & constants ===\n",
        "import re, time, random, pickle\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Dict\n",
        "from functools import lru_cache\n",
        "\n",
        "ALPH = [chr(i) for i in range(ord('a'), ord('z')+1)]\n",
        "PAD = \"^\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 2: Load + Clean + Bucket Corpus ===\n",
        "from google.colab import files\n",
        "print(\"Upload corpus.txt (train) and test.txt (eval).\")\n",
        "_ = files.upload()\n",
        "\n",
        "ALPH_RE = re.compile(r'[^a-zA-Z]+')\n",
        "\n",
        "def clean_word(raw: str) -> str:\n",
        "    w = ALPH_RE.sub('', raw).lower()\n",
        "    return w if len(w) >= 3 else ''\n",
        "\n",
        "def load_corpus(path: str) -> List[str]:\n",
        "    out=[]\n",
        "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        for line in f:\n",
        "            w = clean_word(line)\n",
        "            if w: out.append(w)  # keep duplicates for natural frequency\n",
        "    if not out: raise ValueError(f\"Empty after cleaning: {path}\")\n",
        "    return out\n",
        "\n",
        "def bucket_words(words: List[str]) -> Dict[str, List[str]]:\n",
        "    B={'S':[], 'M':[], 'L':[]}\n",
        "    for w in words:\n",
        "        n=len(w)\n",
        "        if 3<=n<=5: B['S'].append(w)\n",
        "        elif 6<=n<=8: B['M'].append(w)\n",
        "        elif n>=9:   B['L'].append(w)\n",
        "    return B\n",
        "\n",
        "train_words = load_corpus('corpus.txt')\n",
        "test_words  = load_corpus('test.txt')\n",
        "buckets = bucket_words(train_words)\n",
        "\n",
        "print(\"Train size:\", len(train_words))\n",
        "print(\"Buckets:\", {k:len(v) for k,v in buckets.items()})\n",
        "print(\"Test size:\", len(test_words))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "qRdj1dVZ_-LX",
        "outputId": "c12e2c3d-aa3c-4d69-e36f-9b33bb13639d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload corpus.txt (train) and test.txt (eval).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-089bde34-f04f-4f65-ae5f-22f1dda5d756\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-089bde34-f04f-4f65-ae5f-22f1dda5d756\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving corpus.txt to corpus.txt\n",
            "Saving test.txt to test.txt\n",
            "Train size: 49870\n",
            "Buckets: {'S': 3897, 'M': 15235, 'L': 30738}\n",
            "Test size: 1998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 3: Candidate index ===\n",
        "class CorpusIndex:\n",
        "    def __init__(self, words: List[str]):\n",
        "        self.by_len = defaultdict(list)\n",
        "        for w in words:\n",
        "            self.by_len[len(w)].append(w)\n",
        "\n",
        "    def filter(self, mask: str, wrong: set, right: set):\n",
        "        pool = self.by_len[len(mask)]\n",
        "        wrong = set(wrong)\n",
        "        fixed = [(i,c) for i,c in enumerate(mask) if c!='_']\n",
        "        out=[]\n",
        "        for w in pool:\n",
        "            if wrong and any(ch in wrong for ch in w):\n",
        "                continue\n",
        "            ok=True\n",
        "            for i,c in fixed:\n",
        "                if w[i]!=c:\n",
        "                    ok=False; break\n",
        "            if ok: out.append(w)\n",
        "        return out\n",
        "\n",
        "idx_train = CorpusIndex(train_words)\n",
        "idx_eval  = CorpusIndex(test_words)\n"
      ],
      "metadata": {
        "id": "k0OhPwDRADIA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 4: NGramHMM (trigram) ===\n",
        "def len_bucket(n:int)->str:\n",
        "    return \"S\" if 3<=n<=5 else (\"M\" if 6<=n<=8 else \"L\")\n",
        "\n",
        "class NGramHMM:\n",
        "    def __init__(self, n=3, k=0.5, lam=0.6, cand_cap=1500, work_cap=120_000):\n",
        "        self.n=n; self.k=k; self.lam=lam\n",
        "        self.cand_cap=cand_cap; self.work_cap=work_cap\n",
        "        self.ctx_counts={\"S\":defaultdict(Counter),\"M\":defaultdict(Counter),\"L\":defaultdict(Counter)}\n",
        "        self.global_prior={\"S\":{a:1/26 for a in ALPH},\n",
        "                           \"M\":{a:1/26 for a in ALPH},\n",
        "                           \"L\":{a:1/26 for a in ALPH}}\n",
        "\n",
        "    def fit(self, words_by_bucket: Dict[str, List[str]]):\n",
        "        n=self.n\n",
        "        for bk, ws in words_by_bucket.items():\n",
        "            cc=self.ctx_counts[bk]; gl=Counter()\n",
        "            for w in ws:\n",
        "                gl.update(w)\n",
        "                s = PAD*(n-1)+w\n",
        "                for i in range(n-1, len(s)):\n",
        "                    ctx = s[i-n+1:i]\n",
        "                    nxt = s[i]\n",
        "                    if nxt.isalpha():\n",
        "                        cc[ctx][nxt]+=1\n",
        "            tot=sum(gl.values()) or 1\n",
        "            self.global_prior[bk] = {a: gl.get(a,0)/tot for a in ALPH}\n",
        "\n",
        "    @lru_cache(maxsize=200_000)\n",
        "    def _ctx_probs(self, bk:str, ctx:str):\n",
        "        counts = self.ctx_counts[bk].get(ctx, Counter())\n",
        "        tot = sum(counts.values()) + self.k*26\n",
        "        inv = 1.0/tot\n",
        "        return tuple((counts.get(a,0)+self.k)*inv for a in ALPH)\n",
        "\n",
        "    def _pcand(self, candidates: List[str], mask: str):\n",
        "        agg=Counter(); support=set()\n",
        "        for w in candidates:\n",
        "            for i,ch in enumerate(w):\n",
        "                if mask[i]=='_':\n",
        "                    agg[ch]+=1\n",
        "                    support.add(ch)\n",
        "        Z = sum(agg.values()) or 1\n",
        "        return {a: agg.get(a,0)/Z for a in ALPH}, support\n",
        "\n",
        "    def _phmm(self, candidates: List[str], mask: str, bk: str):\n",
        "        n=self.n\n",
        "        blanks=[i for i,c in enumerate(mask) if c=='_']\n",
        "        if not blanks:\n",
        "            return {a:1/26 for a in ALPH}\n",
        "        work = len(candidates)*len(blanks)\n",
        "        if work > self.work_cap:\n",
        "            cap=min(self.cand_cap, len(candidates))\n",
        "            step=max(1, len(candidates)//cap)\n",
        "            candidates = candidates[::step][:cap]\n",
        "        ctx_count=Counter()\n",
        "        pad = PAD*(n-1)\n",
        "        for w in candidates:\n",
        "            s = pad + w\n",
        "            for i in blanks:\n",
        "                j = i+(n-1)\n",
        "                ctx = s[j-n+1:j]\n",
        "                ctx_count[ctx]+=1\n",
        "        if not ctx_count:\n",
        "            return {a:1/26 for a in ALPH}\n",
        "        agg=[0.0]*26; total=0\n",
        "        for ctx,cnt in ctx_count.items():\n",
        "            probs = self._ctx_probs(bk, ctx)\n",
        "            for k in range(26):\n",
        "                agg[k]+=cnt*probs[k]\n",
        "            total+=cnt\n",
        "        inv=1.0/(total or 1.0)\n",
        "        return {ALPH[i]: agg[i]*inv for i in range(26)}\n",
        "\n",
        "    def blended_letter_probs(self, candidates: List[str], mask: str, lam=None):\n",
        "        if not candidates:\n",
        "            u=1.0/26\n",
        "            return {a:u for a in ALPH}\n",
        "        bk = len_bucket(len(mask))\n",
        "        lam = self.lam if lam is None else lam\n",
        "        pc, support = self._pcand(candidates, mask)\n",
        "        ph = self._phmm(candidates, mask, bk)\n",
        "        prior = self.global_prior[bk]\n",
        "\n",
        "        alpha, beta, gamma = lam, 0.25, max(0.0, 1.0-lam-0.25)\n",
        "        out={}\n",
        "        for a in ALPH:\n",
        "            if a not in support:\n",
        "                out[a]=0.0\n",
        "            else:\n",
        "                out[a] = alpha*pc.get(a,0.0) + beta*ph.get(a,0.0) + gamma*prior.get(a,0.0)\n",
        "        Z=sum(out.values()) or 1.0\n",
        "        for a in ALPH:\n",
        "            out[a]/=Z\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "7TD5Xha0AUuF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 5: Hangman Environment ===\n",
        "class HangmanEnv:\n",
        "    def __init__(self, word: str, lives: int = 6):\n",
        "        self.word = word\n",
        "        self.start_l = lives\n",
        "        self.reset(word)\n",
        "\n",
        "    def reset(self, word=None):\n",
        "        if word is not None:\n",
        "            self.word = word\n",
        "        self.lives = self.start_l\n",
        "        self.mask = ['_']*len(self.word)\n",
        "        self.guessed = set()\n",
        "        return ''.join(self.mask)\n",
        "\n",
        "    def step(self, letter: str):\n",
        "        info={}\n",
        "        if letter in self.guessed:\n",
        "            info['repeat']=True\n",
        "            return ''.join(self.mask), 0, False, info\n",
        "        self.guessed.add(letter)\n",
        "        hits=0\n",
        "        for i,ch in enumerate(self.word):\n",
        "            if ch==letter:\n",
        "                self.mask[i]=ch\n",
        "                hits+=1\n",
        "        if hits>0:\n",
        "            done = '_' not in self.mask\n",
        "            reward = 2*hits + (10 if done else 0)\n",
        "            return ''.join(self.mask), reward, done, info\n",
        "        else:\n",
        "            self.lives -= 1\n",
        "            done = self.lives==0\n",
        "            reward = -1 + (-10 if done else 0)\n",
        "            return ''.join(self.mask), reward, done, info\n"
      ],
      "metadata": {
        "id": "nYp9HaIQAp_U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 6: Original greedy HMM policy ===\n",
        "def greedy_play(word, idx, hmm, lives=6):\n",
        "    env = HangmanEnv(word, lives)\n",
        "    wrong=set(); right=set()\n",
        "\n",
        "    while True:\n",
        "        mask = ''.join(env.mask)\n",
        "        candidates = idx.filter(mask, wrong, right)\n",
        "        probs = hmm.blended_letter_probs(candidates, mask)\n",
        "\n",
        "        letter = max((a for a in ALPH if a not in env.guessed),\n",
        "                     key=lambda a: probs.get(a,0.0))\n",
        "\n",
        "        _, _, done, _ = env.step(letter)\n",
        "\n",
        "        if letter in word:\n",
        "            right.add(letter)\n",
        "        else:\n",
        "            wrong.add(letter)\n",
        "\n",
        "        if done:\n",
        "            win = '_' not in env.mask\n",
        "            wrong_guesses = sum(1 for g in env.guessed if g not in set(word))\n",
        "            correct_guesses = len(right)\n",
        "            return win, wrong_guesses, correct_guesses\n"
      ],
      "metadata": {
        "id": "It_Qs_zSAsil"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 7: Train HMM ===\n",
        "hmm = NGramHMM(n=3, k=0.5, lam=0.6)\n",
        "hmm.fit(buckets)\n",
        "\n",
        "print(\"✅ HMM trained.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnKuavUGBUpM",
        "outputId": "fe1d3435-5313-4db7-c17c-a31137644fba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ HMM trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 8: Smoke test ===\n",
        "random.seed(7)\n",
        "sample = [random.choice(test_words) for _ in range(5)]\n",
        "t0=time.time()\n",
        "for w in sample:\n",
        "    win, wrong, correct = greedy_play(w, idx_eval, hmm)\n",
        "    print(f\"{w} -> {'WIN' if win else 'LOSE'} | wrong={wrong} correct={correct}\")\n",
        "print(\"Time:\", time.time()-t0, \"s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS3l5XXRBXYk",
        "outputId": "35b2e01e-4894-482a-8e8d-72b6773a977f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "locomobility -> WIN | wrong=1 correct=8\n",
            "unshapeliness -> WIN | wrong=0 correct=9\n",
            "presurvey -> WIN | wrong=1 correct=7\n",
            "viperina -> WIN | wrong=0 correct=7\n",
            "chaetotactic -> WIN | wrong=1 correct=7\n",
            "Time: 0.021682024002075195 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ead5fd0",
        "outputId": "c6f7ead7-f2c0-44c6-d48f-4d783c5c7f4d"
      },
      "source": [
        "# === CELL 9: Eval with accuracy ===\n",
        "def eval_greedy(words, episodes=200):\n",
        "    wins=0\n",
        "    total_wrong=0\n",
        "    total_correct=0\n",
        "    t0=time.time()\n",
        "    for _ in range(episodes):\n",
        "        w = random.choice(words)\n",
        "        win, wrong, correct = greedy_play(w, idx_eval, hmm)\n",
        "        wins += int(win)\n",
        "        total_wrong += wrong\n",
        "        total_correct += correct\n",
        "    dt=time.time()-t0\n",
        "    total_guesses = total_correct + total_wrong\n",
        "    accuracy = (total_correct / total_guesses) if total_guesses>0 else 0.0\n",
        "    result = {\n",
        "        \"episodes\": episodes,\n",
        "        \"success_rate\": wins/episodes,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"total_correct\": total_correct,\n",
        "        \"total_wrong\": total_wrong,\n",
        "        \"final_score\": (wins/episodes)*2000 - total_wrong*5,\n",
        "        \"time_sec\": dt\n",
        "    }\n",
        "    return result\n",
        "\n",
        "res200 = eval_greedy(test_words, episodes=200)\n",
        "res200\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'episodes': 200,\n",
              " 'success_rate': 1.0,\n",
              " 'accuracy': 0.9060481503229595,\n",
              " 'total_correct': 1543,\n",
              " 'total_wrong': 160,\n",
              " 'final_score': 1200.0,\n",
              " 'time_sec': 0.5900607109069824}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b9049fd",
        "outputId": "2c7f2628-d18a-4d8e-b262-3dc3a743b7e1"
      },
      "source": [
        "# === CELL 10: 2000-game evaluation ===\n",
        "res2000 = eval_greedy(test_words, episodes=2000)\n",
        "print(res2000)\n",
        "print(f\"Accuracy %: {res2000['accuracy']*100:.2f}%\")\n",
        "print(f\"Success Rate %: {res2000['success_rate']*100:.2f}%\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'episodes': 2000, 'success_rate': 1.0, 'accuracy': 0.9043576347660888, 'total_correct': 15233, 'total_wrong': 1611, 'final_score': -6055.0, 'time_sec': 6.932491064071655}\n",
            "Accuracy %: 90.44%\n",
            "Success Rate %: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 11: Save HMM + index for RL ===\n",
        "rl_assets = {\n",
        "    \"hmm\": hmm,\n",
        "    \"idx_eval\": idx_eval,\n",
        "    \"alphabet\": ALPH\n",
        "}\n",
        "\n",
        "with open(\"rl_assets.pkl\", \"wb\") as f:\n",
        "    pickle.dump(rl_assets, f)\n",
        "\n",
        "print(\"✅ Saved rl_assets.pkl (HMM + index + alphabet)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t_RE4MZYq7I",
        "outputId": "42aa125f-69a3-49cb-a200-42a2ab7df126"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved rl_assets.pkl (HMM + index + alphabet)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 13 (FINAL): RL ENV WITH CONTEST-ALIGNED REWARD ===\n",
        "\n",
        "class RLHangmanEnv:\n",
        "    def __init__(self, word, idx, hmm, lives=6):\n",
        "        self.idx = idx\n",
        "        self.hmm = hmm\n",
        "        self.base = HangmanEnv(word, lives)\n",
        "        self.word = word\n",
        "        self.wrong = 0\n",
        "        self.repeats = 0\n",
        "\n",
        "    def _candidate_stats(self, mask):\n",
        "        cands = self.idx.filter(mask,\n",
        "                                {g for g in self.base.guessed if g not in set(self.word)},\n",
        "                                {g for g in self.base.guessed if g in set(self.word)})\n",
        "        pc, _ = self.hmm._pcand(cands, mask)\n",
        "        prior = self.hmm.global_prior[len_bucket(len(mask))]\n",
        "        pc_vec    = np.array([pc[a]    for a in ALPH], dtype=np.float32)\n",
        "        prior_vec = np.array([prior[a] for a in ALPH], dtype=np.float32)\n",
        "        return cands, pc_vec, prior_vec\n",
        "\n",
        "    def state(self):\n",
        "        mask_str = ''.join(self.base.mask)\n",
        "        cands, pc_vec, prior_vec = self._candidate_stats(mask_str)\n",
        "        hmm_probs = self.hmm.blended_letter_probs(cands, mask_str)\n",
        "        hmm_vec = np.array([hmm_probs[a] for a in ALPH], dtype=np.float32)\n",
        "\n",
        "        x = np.concatenate([\n",
        "            encode_mask_fixed(mask_str),\n",
        "            encode_guessed(self.base.guessed),\n",
        "            np.array([self.base.lives], np.float32) / 6.0,\n",
        "            hmm_vec,\n",
        "            pc_vec,\n",
        "            prior_vec,\n",
        "            bucket_onehot(len(mask_str))\n",
        "        ], axis=0)\n",
        "        return x\n",
        "\n",
        "    def valid_actions(self):\n",
        "        return [i for i, a in enumerate(ALPH) if a not in self.base.guessed]\n",
        "\n",
        "    def step(self, action_idx: int):\n",
        "        a = ALPH[action_idx]\n",
        "\n",
        "        # ---- REPEAT HANDLING ----\n",
        "        if a in self.base.guessed:\n",
        "            self.repeats += 1\n",
        "            return self.state(), -2.0, False, {}   # repeat = -2 penalty\n",
        "\n",
        "        prev_mask = ''.join(self.base.mask)\n",
        "        _, _, done, _ = self.base.step(a)\n",
        "        new_mask = ''.join(self.base.mask)\n",
        "\n",
        "        k = sum(1 for i in range(len(new_mask))\n",
        "                  if new_mask[i] != prev_mask[i] and new_mask[i] != '_')\n",
        "\n",
        "        # ---- REWARD LOGIC (aligned with contest scoring) ----\n",
        "        if a in self.word:\n",
        "            r = 2.5 * k          # reward per correct reveal\n",
        "        else:\n",
        "            r = -8.0             # strong penalty for wrong guess\n",
        "            self.wrong += 1\n",
        "\n",
        "        r -= 0.25                # per-step penalty → shorter games rewarded\n",
        "\n",
        "        if done:\n",
        "            if \"_\" not in new_mask:     # WIN\n",
        "                r += 15.0\n",
        "                if self.wrong == 0:\n",
        "                    r += 10.0          # perfect game bonus\n",
        "            else:                       # LOSE\n",
        "                r -= 10.0\n",
        "\n",
        "        return self.state(), r, done, {}\n"
      ],
      "metadata": {
        "id": "ymg0004s2P4G"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 14: DQN Model + Replay Buffer + Masked Action Selection ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import random\n",
        "\n",
        "class QNet(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512), nn.ReLU(),\n",
        "            nn.Linear(512, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 128), nn.ReLU(),\n",
        "            nn.Linear(128, out_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Replay:\n",
        "    def __init__(self, cap=80000):\n",
        "        self.buf = deque(maxlen=cap)\n",
        "    def push(self, *trans): self.buf.append(trans)\n",
        "    def sample(self, batch): return random.sample(self.buf, batch)\n",
        "    def __len__(self): return len(self.buf)\n",
        "\n",
        "def masked_action(q_values, valid_actions):\n",
        "    q = q_values.clone()\n",
        "    mask = torch.full_like(q, -1e9)\n",
        "    mask[valid_actions] = 0\n",
        "    return (q + mask).argmax().item()\n",
        "\n",
        "def select_action(qnet, state, valid_actions, eps):\n",
        "    if random.random() < eps:\n",
        "        return random.choice(valid_actions)\n",
        "    with torch.no_grad():\n",
        "        q = qnet(torch.from_numpy(state).unsqueeze(0).to(device))\n",
        "        return masked_action(q.squeeze(0), valid_actions)\n"
      ],
      "metadata": {
        "id": "mOq_jQ082UL4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 15 (FINAL): CURRICULUM TRAINING S → M → L ===\n",
        "import random\n",
        "from tqdm import trange\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Build dummy env to compute state dimension\n",
        "_tmp = RLHangmanEnv(random.choice(test_words), idx_eval, hmm)\n",
        "state_dim = _tmp.state().shape[0]\n",
        "del _tmp\n",
        "\n",
        "action_dim = 26\n",
        "qnet = QNet(state_dim, action_dim).to(device)\n",
        "tgt  = QNet(state_dim, action_dim).to(device)\n",
        "tgt.load_state_dict(qnet.state_dict())\n",
        "\n",
        "opt = optim.Adam(qnet.parameters(), lr=1e-3)\n",
        "replay = Replay(cap=120000)\n",
        "gamma = 0.99\n",
        "batch = 256\n",
        "sync_rate = 700\n",
        "\n",
        "# ---------------- STAGE TRAINER ----------------\n",
        "def train_stage(words, episodes, eps_start, eps_end, stage_name):\n",
        "    print(f\"\\n=== TRAINING STAGE: {stage_name} ({episodes} episodes) ===\")\n",
        "    wrong_sum = 0; wins = 0; step = 0; losses = []\n",
        "\n",
        "    for ep in trange(episodes):\n",
        "        eps = max(eps_end, eps_start - (eps_start - eps_end) * ep / episodes)\n",
        "        word = random.choice(words)\n",
        "        env = RLHangmanEnv(word, idx_eval, hmm)\n",
        "        s = env.state()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            valid = env.valid_actions()\n",
        "            a = select_action(qnet, s, valid, eps)\n",
        "            s2, r, done, _ = env.step(a)\n",
        "            replay.push(s, a, r, s2, done, valid)\n",
        "            s = s2\n",
        "\n",
        "            if len(replay) >= batch:\n",
        "                # train DQN\n",
        "                batch_data = replay.sample(batch)\n",
        "                ss, aa, rr, ss2, dd, _valid = zip(*batch_data)\n",
        "                ss  = torch.tensor(np.stack(ss), dtype=torch.float32).to(device)\n",
        "                aa  = torch.tensor(aa, dtype=torch.int64).unsqueeze(1).to(device)\n",
        "                rr  = torch.tensor(rr, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "                ss2 = torch.tensor(np.stack(ss2), dtype=torch.float32).to(device)\n",
        "                dd  = torch.tensor(dd, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "                q = qnet(ss).gather(1, aa)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    q2 = tgt(ss2).max(dim=1, keepdim=True)[0]\n",
        "                    y = rr + gamma * (1 - dd) * q2\n",
        "\n",
        "                loss = nn.SmoothL1Loss()(q, y)\n",
        "                opt.zero_grad(); loss.backward(); opt.step()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                step += 1\n",
        "                if step % sync_rate == 0:\n",
        "                    tgt.load_state_dict(qnet.state_dict())\n",
        "\n",
        "        wrong_sum += env.wrong\n",
        "        if \"_\" not in ''.join(env.base.mask):\n",
        "            wins += 1\n",
        "\n",
        "    print(f\"Stage: {stage_name} | Win rate={wins/episodes:.3f} | Avg wrong={wrong_sum/episodes:.3f}\")\n",
        "    return losses\n",
        "\n",
        "# ---------------- CURRICULUM RUN ----------------\n",
        "\n",
        "loss_hist = []\n",
        "loss_hist += train_stage(buckets[\"S\"], 5000, eps_start=0.5, eps_end=0.15, stage_name=\"SHORT (3-5)\")\n",
        "loss_hist += train_stage(buckets[\"M\"], 6000, eps_start=0.3, eps_end=0.1, stage_name=\"MEDIUM (6-8)\")\n",
        "loss_hist += train_stage(buckets[\"L\"], 7000, eps_start=0.2, eps_end=0.05, stage_name=\"LONG (9+)\")\n",
        "\n",
        "# ---------------- SAVE FINAL MODEL ----------------\n",
        "import pickle\n",
        "with open(\"rl_curriculum_final.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"qnet_state\": qnet.state_dict(),\n",
        "        \"state_dim\": state_dim,\n",
        "        \"action_dim\": action_dim\n",
        "    }, f)\n",
        "\n",
        "print(\"\\n✅ Saved final agent: rl_curriculum_final.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEibST8c2XqY",
        "outputId": "c3a47a3b-9e59-47a5-c0ad-7ffbde31c1cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAINING STAGE: SHORT (3-5) (5000 episodes) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [03:17<00:00, 25.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage: SHORT (3-5) | Win rate=0.026 | Avg wrong=5.950\n",
            "\n",
            "=== TRAINING STAGE: MEDIUM (6-8) (6000 episodes) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [05:24<00:00, 18.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage: MEDIUM (6-8) | Win rate=0.017 | Avg wrong=5.970\n",
            "\n",
            "=== TRAINING STAGE: LONG (9+) (7000 episodes) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7000/7000 [08:57<00:00, 13.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage: LONG (9+) | Win rate=0.032 | Avg wrong=5.947\n",
            "\n",
            "✅ Saved final agent: rl_curriculum_final.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL: Evaluate RL on /content/test.txt (one pass over file) ===\n",
        "import os, pickle, torch, numpy as np\n",
        "\n",
        "TEST_PATH = \"/content/test.txt\"\n",
        "\n",
        "# 1) Load & clean\n",
        "ALPH_RE = re.compile(r'[^a-zA-Z]+')\n",
        "\n",
        "def clean_word_eval(raw: str) -> str:\n",
        "    w = ALPH_RE.sub('', raw).lower()\n",
        "    return w if len(w) >= 3 else ''\n",
        "\n",
        "if not os.path.exists(TEST_PATH):\n",
        "    raise FileNotFoundError(f\"Couldn't find {TEST_PATH}. Upload it or fix the path.\")\n",
        "\n",
        "test_words_custom = []\n",
        "with open(TEST_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for line in f:\n",
        "        w = clean_word_eval(line)\n",
        "        if w:\n",
        "            test_words_custom.append(w)\n",
        "\n",
        "if not test_words_custom:\n",
        "    raise ValueError(\"test.txt cleaned to empty. Check file contents.\")\n",
        "\n",
        "# 2) Build a fresh index for this test set\n",
        "idx_eval_custom = CorpusIndex(test_words_custom)\n",
        "\n",
        "# 3) Load the final RL model if not already in memory\n",
        "try:\n",
        "    qnet_final\n",
        "except NameError:\n",
        "    # fallback: load the model you saved as rl_agent.pkl (overwritten to be your final)\n",
        "    with open(\"rl_curriculum_final.pkl\", \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "    state_dim = data[\"state_dim\"]; action_dim = data[\"action_dim\"]\n",
        "    qnet_final = QNet(state_dim, action_dim).to(device)\n",
        "    qnet_final.load_state_dict(data[\"qnet_state\"])\n",
        "    qnet_final.eval()\n",
        "\n",
        "# 4) Evaluate exactly once per word (contest scoring)\n",
        "def eval_on_list(words):\n",
        "    wins = 0\n",
        "    wrong_total = 0\n",
        "    repeats_total = 0\n",
        "\n",
        "    for w in words:\n",
        "        env = RLHangmanEnv(w, idx_eval_custom, hmm)  # same HMM oracle, new index\n",
        "        s = env.state()\n",
        "        done = False\n",
        "        # play until done (cap for safety)\n",
        "        for _ in range(60):\n",
        "            valid = env.valid_actions()\n",
        "            # masked greedy action from the trained net\n",
        "            with torch.no_grad():\n",
        "                qvals = qnet_final(torch.tensor(s, dtype=torch.float32, device=device).unsqueeze(0))[0].cpu().numpy()\n",
        "            # choose best among valid\n",
        "            a = valid[int(np.argmax(qvals[valid]))]\n",
        "            s, _, done, _ = env.step(a)\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        wrong_total += env.wrong\n",
        "        repeats_total += env.repeats  # should be 0 because we mask, but we count it anyway\n",
        "        if \"_\" not in ''.join(env.base.mask):\n",
        "            wins += 1\n",
        "\n",
        "    games = len(words)\n",
        "    sr = wins / games\n",
        "    score = (sr * 2000) - (wrong_total * 5) - (repeats_total * 2)\n",
        "    return {\n",
        "        \"games\": games,\n",
        "        \"success_rate\": sr,\n",
        "        \"total_wrong\": wrong_total,\n",
        "        \"total_repeats\": repeats_total,\n",
        "        \"final_score\": score\n",
        "    }\n",
        "\n",
        "results_custom = eval_on_list(test_words_custom)\n",
        "print(\"Test file:\", TEST_PATH)\n",
        "print(results_custom)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NDBD6JvAkAE",
        "outputId": "276ae4c3-8fce-4995-f2b8-c2934045e497"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test file: /content/test.txt\n",
            "{'games': 1998, 'success_rate': 0.8273273273273273, 'total_wrong': 7915, 'total_repeats': 0, 'final_score': -37920.34534534535}\n"
          ]
        }
      ]
    }
  ]
}